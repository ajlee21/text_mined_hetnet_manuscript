## Results

### Generative Model Using Randomly Sampled Label Functions
![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each generative model trained on randomly sampled label functions.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function is sampled from.
For example, the top-left most square depicts the generative model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship. 
The square towards the right depicts the generative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](https://raw.githubusercontent.com/greenelab/snorkeling/master/figures/label_sampling_experiment/transfer_test_set_auroc.png){#fig:gen_model_auroc}

We added randomly sampled label functions to a baseline for each edge type to evaluate the feasibility of label function re-use.
Our baseline model consisted of a generative model trained with only the edge type's distant supervision label functions.
We report the results in the form of area under the precision recall curve (AUPR) (Figure {@fig:gen_model_auprc}) and area under the receiver operating curve (AUROC) (Figure {@fig:gen_model_auroc}).  
The on-diagonal plots of figure {@fig:gen_model_auprc}) and figure {@fig:gen_model_auprc} show performance when edge-specific label functions are added on top of edge-specific baselines.
The general trend is performance increases in this setting.
The Compound-treats-Disease (CtD) edge type is a quintessential example of this trend.
The baseline model starts off with an AUROC score of 52% and an AUPRC of 28%, which increase to 76% and 49% respectively as more CtD label functions are included. 
Disease-associates-Gene (DaG) edges have a similar trend: performance starting off with a AUROC of 56% and AUPRC of 41%, which increase to 62% and 45% respectively.
Both the Compound-binds-Gene (CbG) and Gene-interacts-Gene (GiG) edges have an increasing trend but plateau after a few label functions are added.  

The off-diagonals in figure {@fig:gen_model_auprc}) and figure {@fig:gen_model_auprc} show how performance varies when label functions from one edge type are added to a different edge type's baseline.
In certain cases (apparent for DaG), performance increases regardless of the edge type used for label functions.
In other cases (apparent with CtD), one label function appears to improve performance; however, adding more label functions does not improve performance (AUROC) or decreases it (AUPRC).
In certain cases, the source of the label functions appear to be important: for CbG edges performance decreases when using label functions from the DaG and CtD categories.

Our initial hypothesis was based on the idea that certain edge types capture similar physical relationships and that these cases would be particularly amenable for label function transfer.
For example, Compound-binds-Gene (CbG) and Gene-interacts-Gene (GiG) both describe physical interactions.
We observed that performance increased as assessed by both AUPRC and AUPRC when using label functions from the GiG edge type to predict CbG edges.
A similar trend was observed when predicting the GiG edge; however, the performance differences were small for this edge type making the importance difficult to assess.  
The last column shows performance when sampling from all label functions.
Performance increased (AUROC and AUPRC) for both DaG and CtD, when sampling from the full pool of label functions.
CbG and GiG also had increased performance when one random label function was sampled, but performance decreased drastically as more label functions were added.
It is possible that a small number of irrelevant label functions are able to overwhelm the distant supervision label functions in these cases.

![
Grid of Area Under the Precision Recall Curve (AUPRC) scores for each generative model trained on randomly sampled label functions.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function is sampled from.
For example, the top-left most square depicts the generative model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship. 
The square towards the right depicts the generative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](https://raw.githubusercontent.com/greenelab/snorkeling/master/figures/label_sampling_experiment/transfer_test_set_auprc.png){#fig:gen_model_auprc}

### Random Label Function Gen Model Analysis
![
A grid of area under the receiver operating curve (AUROC) for each edge type.
Each plot consists of adding a single label function on top of the baseline model.
This label function emits a positive (top row) or negative (bottom row) label at specified frequencies, and performance at zero is equivalent to not having a randomly emitting label function.
The error bars represent 95% confidence intervals for AUROC (y-axis) at each emission frequency.
](https://raw.githubusercontent.com/danich1/snorkeling/f8962788e462b783be05a6dec5eec7fe0f0259e7/figures/gen_model_error_analysis/transfer_test_set_auroc.png){#fig:random_label_function_auroc}

We observed that including one label function of a mismatched type to distant supervision often improved performance, so we evaluated the effects of adding a random label function in the same setting.
We found that adding random noise did not usually improve performance (Figures {@fig:random_label_function_auprc} and {@fig:random_label_function_auprc}).
For the CbG edge type we did observe slightly increased performance via AUPR (Figure {@fig:random_label_function_auprc}).
However, in general the performance changes were smaller than those observed with mismatched label types.

![
A grid of area under the precision recall curve (AUPR) for each edge type.
Each plot consists of adding a single label function on top of the baseline model.
This label function emits a positive (top row) or negative (bottom row) label at specified frequencies.
The error bars represent 95% confidence intervals for AUPR (y-axis) at emission frequency.
](https://raw.githubusercontent.com/danich1/snorkeling/f8962788e462b783be05a6dec5eec7fe0f0259e7/figures/gen_model_error_analysis/transfer_test_set_auprc.png){#fig:random_label_function_auprc}


## Discriminator Model Builds Off Generative Model
place the grid of aurocs here for discriminator model

## Random Noise Generative Model
place the results of random label function experiment


### Reconstructing Hetionet

Once the discriminiative model has been calibrated, we compared our model to a baseline model [@tag:cocoscore] (Figure {@fig:cocoscore_comparison}) and  estimated the number of edges that can be added/recalled from Hetionet v1 (Figure Figure {@fig:hetionet_reconstruction}).
Regarding model comparison we evaluated edge prediction performance using all edges assigned to our test set.
Scores for both models are reported in the form of area under the receiver operative curve (AUROC) and area under the precision recall curve (AUPR).
The baseline model outperforms our model for majority of edge types.
Our model achieves an AUROC of 78% and an AUPR of 28% for Disease-associates-Gene (DaG), while the baseline model achieves a score of 82% and 45% resepctively.
For Gene-interacts-Gene the baseline model achieved an AUROC of 73% and an AUPR of 11%, while our model achieved an AUROC of 72% and an AUPR of 7%.
Our model out performed the literature model for Compound-treats-Disease (CtD) by obtaining an AUROC of 94% and an AUPR of 40%.
The baseline model achieved an AUROC of 89% and an AUPR of 28%.
The baseline model achieved an AUROC of 74% and AUPR of 11% for Compound-binds-Gene (CbG), while our model achieved an AUROC of 73% and an AUPR of 8%.  
Despite model performance, we are still able to add new edges to Hetionet v1.
For DaG we are able to recall 4 already established edges with 100% precision.
At precision of 60% we can add 14 new edges to Hetionet v1.
With CtD we can recall 2 already establed edges with 100% precision and as precision level decreases to 60% we can add 2 new edges.
Both CbG and GiG the models have a drastic decrease as the precision level increases to 50%.
We were able to recall one existing edge for both edge types with 100% precision. 
Despite the low performance, we are still able to add a few new edges to Hetionet v1.

![
Comparion between our model and CoCoScore model [@tag:cocoscore].
We report both model's performance in terms of area under the receiver operating curve (AUROC) and area under then precision recall curve (AUPR).
Our model achieves comparable performance against CoCoScore in terms of AUROC.
As for AUPR CoCoScore consistently outperforms our model except for compound treats disease (CtD). 
](https://raw.githubusercontent.com/danich1/snorkeling/4259f2a1336c42f89023effd9f9ff598dee744e3/figures/literature_models/model_comparison.png){#fig:cocoscore_comparison}

![
A scatter plot showing the number of edges (log scale) we can add or recall given the precision level. 
The blue depicts edges exisiting in hetionet and the orange depicts how many novel edges can be added to hetionet.
Note that some edge types do not reach 100% precision.
](https://raw.githubusercontent.com/danich1/snorkeling/240384c6e7cf69e784516688986748ea2fad255d/figures/edge_prediction_experiment/edges_added.png){#fig:hetionet_reconstruction}


