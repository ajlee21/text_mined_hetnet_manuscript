# Results

## Random Sampling of Generative Model
place the grid aurocs here for generative model

## Discriminator Model Builds Off Generative Model
We evaluate how well the discriminator model builds off of the generative model.
In the top left square the discriminative model's performance correlates with the generative model. 
As the number of text pattern label functions are added towards the generative model the discriminative model improves. 
In the off diagonals the discriminative model has variable performance depending on the generative model.
As the amount of irrelevant label functions increases corresponds to higher noise levels.
Strange enough in with the compound binds gene group there is a spike in performance when added one random label function.
Despite this phenomon the performance continues to decrease as the number of irrelevant label functions continues to be added. 
For predicting compound binds gene label functions designed to predict gig aid in discriminative model performance.
The overall trend is that the more relevant the generative model is the better the performance.
With compound treats disesae the discriminative model performs better when using the generative model trained on database functions alone.
The best reported model for each relationship is the one using the relevant functions alone.
 
![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each discriminative model trained using generated labels from the generative models.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function was sampled from. 
For example, the top-left most square depicts the discriminator model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship. 
The square towards the right depicts the discriminative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](images/figures/label_sampling/disc_performance_test_set_auroc.png){#fig:discriminative_model_auroc}

![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each discriminative model trained using generated labels from the generative models.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function was sampled from. 
For example, the top-left most square depicts the discriminator model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship. 
The square towards the right depicts the discriminative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](images/figures/label_sampling/disc_performance_test_set_auprc.png){#fig:discriminative_model_auprc}

## Discriminative Model Calibration
![
Beautiful Description here
](images/figures/model_calibration/model_calibration.png){#fig:discriminative_model_calibration}

## Reconstructing Hetionet
place figure of number of new edges that can be added to hetionet as well as edges we can reconstruct using this method
