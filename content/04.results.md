## Results

### Generative Model Using Randomly Sampled Label Functions
![
Grid of AUROC scores for each generative model trained on randomly sampled label functions.
The rows depict the relationship each model is trying to predict and the columns are the edge type specific sources from which each label function is sampled.
The right most column consists of pooling every relationship specific label function and proceeding as above.
](https://raw.githubusercontent.com/danich1/snorkeling/ee638b4e45717a86f54a2744a813baaa90bc6b84/figures/label_sampling_experiment/transfer_test_set_auroc.png){#fig:auroc_gen_model_performance}

We added randomly sampled label functions to a baseline for each edge type to evaluate the feasibility of label function re-use.
Our baseline model consisted of a generative model trained with only edge-specific distant supervision label functions.
We reported the results in AUROC and AUPR (Figure {@fig:auroc_gen_model_performance} and Supplemental Figure {@fig:aupr_gen_model_performance}).  
The on-diagonal plots of figure {@fig:auroc_gen_model_performance} and supplemental figure {@fig:aupr_gen_model_performance} show increasing performance when edge-specific label functions are added on top of the  edge-specific baselines.
The CtD edge type is a quintessential example of this trend.
The baseline model starts off with an AUROC score of 52% and an AUPRC of 28%, which increase to 76% and 49% respectively as more CtD label functions are included. 
DaG edges have a similar trend: performance starting off with an AUROC of 56% and AUPR of 41% then increases to 62% and 45% respectively.
Both the CbG and GiG edges have an increasing trend but plateau after a few label functions are added.  

The off-diagonals in figure {@fig:auroc_gen_model_performance} and supplemental figure {@fig:aupr_gen_model_performance} show how performance varies when label functions from one edge type are added to a different edge type's baseline.
In certain cases (apparent for DaG), performance increases regardless of the edge type used for label functions.
In other cases (apparent with CtD), one label function appears to improve performance; however, adding more label functions does not improve performance (AUROC) or decreases it (AUPR).
In certain cases, the source of the label functions appears to be important: the performance of CbG edges decrease when using label functions from the DaG and CtD categories.

Our initial hypothesis was based on the idea that certain edge types capture similar physical relationships and that these cases would be particularly amenable for label function transfer.
For example, CbG and GiG both describe physical interactions.
We observed that performance increased as assessed by both AUROC and AUPR when using label functions from the GiG edge type to predict CbG edges.
A similar trend was observed when predicting the GiG edge; however, the performance differences were small for this edge type making the importance difficult to assess.  
The last column shows increasing performance (AUROC and AUPR) for both DaG and CtD when sampling from all label functions.
CbG and GiG also had increased performance when one random label function was sampled, but performance decreased drastically as more label functions were added.
It is possible that a small number of irrelevant label functions are able to overwhelm the distant supervision label functions in these cases (see Figure {@fig:auroc_random_label_function_performance} and Supplemental Figure {@fig:aupr_random_label_function_performance}).

### Random Label Function Generative Model Analysis
![
A grid of AUROC (A) scores for each edge type.
Each plot consists of adding a single label function on top of the baseline model.
This label function emits a positive (shown in blue) or negative (shown in orange) label at specified frequencies, and performance at zero is equivalent to not having a randomly emitting label function.
The error bars represent 95% confidence intervals for AUROC or AUPR (y-axis) at each emission frequency.
](https://raw.githubusercontent.com/danich1/snorkeling/ee638b4e45717a86f54a2744a813baaa90bc6b84/figures/gen_model_error_analysis/transfer_test_set_auroc.png){#fig:auroc_random_label_function_performance}

We observed that including one label function of a mismatched type to distant supervision often improved performance, so we evaluated the effects of adding a random label function in the same setting.
We found that usually adding random noise did not improve performance (Figure {@fig:auroc_random_label_function_performance} and Supplemental Figure {@fig:aupr_random_label_function_performance}).
For the CbG edge type we did observe slightly increased performance via AUPR (Supplemental Figure {@fig:aupr_random_label_function_performance}).
However, performance changes in general were smaller than those observed with mismatched label types.

### Discriminative Model Performance

![
The discriminator model improves together with the generative model as more edge-specific label function are included.
The line plot headers represents the specific edge type the discriminator model is trying to predict.
The x-axis shows the number of randomly sampled label functions that are incorporated on top of the baseline model (point at 0).
The y axis shows the area under the receiver operating curve (AUROC).
Each datapoint represents the average of each 50 sample run and the error bars represent the 95% confidence interval of each run.
The baseline and “All” data points consist of sampling from the entire fixed set of label functions.
This makes the error bars appear flat.
](https://raw.githubusercontent.com/danich1/snorkeling/1941485a02c8aa9972c67d8f9d3ff96acb0f3b7b/figures/disc_model_experiment/disc_model_test_auroc.png){#fig:auroc_discriminative_model_performance}

The discriminator model is designed to augment performance over the generative model by incorporating textual features along with estimated training labels.
The discriminative model is a piecewise convolutional neural network trained over word embeddings (See Methods).
We report the results of the discriminative model using AUROC (Figure {@fig:auroc_discriminative_model_performance} and AUPR (Supplemental Figure {@fig:aupr_discriminative_model_performance}).  
  
We found that the discriminative model generally out-performed the generative model as more edge-specific label functions are incorporated.
The discriminator model's performance is modest when less than eleven edge-specific label functions are added to the baseline model (seen in Disease associates Gene (DaG), Compound binds Gene (CbG) and Gene interacts Gene (GiG)). 
This suggests that a lower bound of at least eleven label functions is needed to generate training labels the discriminator model can effectively utilize.
An exception to this trend is Compound treats Disease (CtD) where the discriminator model out-performs the generative model at all levels of sampling.
Regarding CbG the discriminator model performs subpar with the generative model until all edge-specific label functions are used.
Interestingly, the AUPR for CbG plateaus below the generative model and the decreases when all edge-specific label functions are used (Supplemental Figure {@fig:aupr_discriminative_model_performance}).
This suggests that the discriminator model might be predicting more false positives than we expected.
Despite the CbG trend exception, the discriminator model genereally learns off of the generative model given that an adequate amount of label functions are included in the model.
