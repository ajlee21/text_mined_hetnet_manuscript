# Results

## Random Sampling of Generative Model
place the grid aurocs here for generative model

### Discriminative Model Performance

In this framework we used a generative model trained over label functions to produce probabilistic training labels for each sentence.
Then we train a discriminative model, which has full access to a representation of the text of the sentence, to predict the generated labels.
The discriminative model is a convolutional neural network trained over word embeddings.
We report the results of the discriminative model using AUPR (Figure {@fig:discriminative_model_auprc}) and AUROC (Figure {@fig:discriminative_model_auroc}).    
We found that the discriminative model under-performed the generative model in most cases.
Only for the CtD edge does the discriminative model appear to provide performance above that of the generative model, and that increased performance is only with modest numbers of label functions.
With the full set of label functions, the performance of both remains similar.
The trend observed in the generative model that one or a few mismatched label functions (off-diagonal) improves performance is retained despite the limited performance of the discriminative model.
 

![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each discriminative model trained using generated labels from the generative models.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function was sampled from. 
For example, the top-left most square depicts the discriminator model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship.
The error bars over the points represents the standard deviation between sampled runs.
The square towards the right depicts the discriminative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](https://raw.githubusercontent.com/greenelab/snorkeling/master/figures/label_sampling_experiment/disc_performance_test_set_auroc.png){#fig:discriminative_model_auroc}

![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each discriminative model trained using generated labels from the generative models.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function was sampled from. 
For example, the top-left most square depicts the discriminator model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship.
The error bars over the points represents the standard deviation between sampled runs.
The square towards the right depicts the discriminative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](https://raw.githubusercontent.com/greenelab/snorkeling/master/figures/label_sampling_experiment/disc_performance_test_set_auprc.png){#fig:discriminative_model_auprc}

### Discriminative Model Calibration

Even deep learning models with high precision and recall can be poorly calibrated, and the overconfidence of these models has been noted [@arxiv:1706.04599; @arxiv:1807.00263].
We attempted to calibrate the best performing discriminative model so that we could directly use the emitted probabilities.
We examined the calibration of our existing model (Figure {@fig:discriminative_model_calibration}, blue line).
We found that the DaG and CtG edge types were, though not perfectly calibrated, were somewhat aligned with the ideal calibration lines.
The CbG and GiG edges were poorly calibrated and increasing model certainty did not always lead to an increase in precision.
Applying the calibration algorithm (orange line) did not appear to bring predictions in line with the ideal calibration line, but did capture some of the uncertainty in the GiG edge type.
For this reason we use the measured precision instead of the predicted probabilities when determining how many edges could be added to existing knowledge bases with specified levels of confidence.

![
Calibration plots for the discriminative model.
A perfectly calibrated model would follow the dashed diagonal line.
The blue line represents the predictions before calibration and the orange line shows predictions after calibration. 
](https://raw.githubusercontent.com/greenelab/snorkeling/master/figures/model_calibration_experiment/model_calibration.png){#fig:discriminative_model_calibration}

## Reconstructing Hetionet
place figure of number of new edges that can be added to hetionet as well as edges we can reconstruct using this method
