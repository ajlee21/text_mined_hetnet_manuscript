# Results

## Random Sampling of Generative Model
place the grid aurocs here for generative model

## Discriminator Model Builds Off Generative Model
We evaluate the discriminator model's ability to build off of the generative model.
For each generative model, trained on sampled label functions, we trained a discriminative model.
We report the results of the discriminative model using area under the precision recall curve (AUPRC) (Figure {@fig:discriminative_model_auprc}) and area under the receiver operating curve (AUROC) (Figure {@fig:discriminative_model_auroc}).    
A general trend is that performance increases when the discriminative model is trained using generative models design each edge type. 
In the top left corner of figures {@fig:discriminative_model_auroc} and {@fig:discriminative_model_auprc} the discriminative model underperforms the generative model when only using distant supervision label functions.
The discriminative model over takes the generative model as more label functions are incorporated. 
This similar trend is seen for the Compound treats Disease (CtD) edge type; however, both the generative and discriminative model perform equally instead of one outcompetiting another.
For the Compound binds Gene (CbG) edge type, the discriminative model consistently underperforms the generative model.
Lastly for the Gene interacts Gene (GiG) edge type the discriminative model starts off underperforming the generative model.
Just like with CtD and DaG performance improves as more label functions are added.  
Looking at the off-diagonals in figures {@fig:discriminative_model_auroc} and {@fig:discriminative_model_auprc}, the discriminative model shows variable performance depending on the edge type.
For the DaG row, the discriminative model consistently underperforms the generative model, that is trained using label functions from other edge types. 
The exception towards this trend is when label functions from all edge types are used.
The inverse effect can be seen for CtD row.
The discriminative model starts off out performing the generative model, but then shifts into underperformance as more label functions are added.
For both the CbG and GiG rows performance starts off with an increasing trend, but then either plateaus or sharply declines.
A perfect example of this the described trend can be seen in the last two rows and first two columns.
When one label function is added, performance spikes and then sharply declines as more label functions are added.
Interestingly, the discriminative model does well in prediciting the CbG edge type, when using the generative model trained on GiG label functions.
This trend doesn't hold for the reverse as the discrimintive model slightly underperforms the generative model.
Lastly for CbG and GiG using all label functions didn't aid in the discriminative model performance.

![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each discriminative model trained using generated labels from the generative models.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function was sampled from. 
For example, the top-left most square depicts the discriminator model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship. 
The square towards the right depicts the discriminative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](images/figures/label_sampling/disc_performance_test_set_auroc.png){#fig:discriminative_model_auroc}

![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each discriminative model trained using generated labels from the generative models.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function was sampled from. 
For example, the top-left most square depicts the discriminator model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship. 
The square towards the right depicts the discriminative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](images/figures/label_sampling/disc_performance_test_set_auprc.png){#fig:discriminative_model_auprc}

## Discriminative Model Calibration
Deep learning models can be overconfident in their predictions. 
Based on this notion we calibrated the best performing discriminative model using a temperature scalling algorithm.
For Disease associates Gene (DaG) and Compound treats Disease (CtD) the model is calibrated for high prob predictions.
For Compound binds Gene (CbG) and Gene interacts Gene (GiG) the model does not calibrate well.
The CbG model has the predicted probabilities shrinking into a domain of [0.2, 0.6].
The GiG model predictions were overestimatedm so the calibrated range shrink to be between 0.4 and 0.6.

![
Calibration plots for the discriminative model.
A perfectly calibrated model would show a diagnoal line (dashed).
The blue line represents the predictions before calibration and the orange line shows predictions after calibration. 
](images/figures/model_calibration/model_calibration.png){#fig:discriminative_model_calibration}

## Reconstructing Hetionet
place figure of number of new edges that can be added to hetionet as well as edges we can reconstruct using this method
