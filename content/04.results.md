# Results

## Random Sampling of Generative Model
place the grid aurocs here for generative model

## Discriminator Model Builds Off Generative Model
We evaluate the discriminator model's ability to boost performance off of the generative model.
For each trained generative model we trained a discriminative model.
We report the results of the discriminative model using area under the precision recall curve (AUPRC) (Figure {@fig:discriminative_model_auprc}) and area under the receiver operating curve (AUROC) (Figure {@fig:discriminative_model_auroc}).    
Performance for the discriminative models increases when using generative models trained specifically for each edge type. 
For Disease associates Gene (DaG), the discriminative model under performs the generative model when only using distant supervision label functions.
The discriminative model increases in performance as more label functions are incorporated into the generative model.
When all label functions are used the discriminative model output performs the generative model.
This similar trend is is seen for Compound treats Disease (CtD).
The discriminative model starts off outperforming the generative model, then starts to perform equally with the generative model as the number of label functions increases.
For Compound binds Gene (CbG) the discriminative model on average consistently under-performs the generative model.
As for Gene interacts Gene (GiG) the discriminative model starts off under-performing the generative model, then increases performance as the number of label function increase.
Finally, when all GiG label functions are used the discriminative model has the same performance as the generative model.  
Regarding the off-diagonals the discriminative model has variable performance depending on the edge type.
When predicting DaG, the discriminative model consistently under-performs the generative models that was trained to predict other edge types.
One example would be the discriminative model achieving an auroc of 0.5 when training off of the CtD designed generative model.
The same under-performing trend can be seen for CbG; however, when using the GiG designed generative model, the discriminative model increases performance compared to the baseline model.
For GiG performance follows an increasing trend, but the plateaus as the number of label functions increases.
One exception to this is using the DaG designed generative model.
Performance drastically decreases as the number of label functions increases.
For CtD the discriminative model starts off out performing the generative model, then decreses sharply when using the DaG or GiG designed generative models.
When using the CbG designed generative model performance decreaes but not as shaprly.  
Lastly, when using the generative model trained on all label functions performance can vary.
For DaG the discriminative model starts off under-performing the generative model and the begins to outperform the generative model.
CtD shares a different trend as the number of label functions increases.
For both CbG and GiG the discriminative model increases in perofrmancel, but then starts to decrease as the number of label functions increases.

![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each discriminative model trained using generated labels from the generative models.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function was sampled from. 
For example, the top-left most square depicts the discriminator model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship. 
The square towards the right depicts the discriminative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](images/figures/label_sampling/disc_performance_test_set_auroc.png){#fig:discriminative_model_auroc}

![
Grid of Area Under the Receiver Operating Curve (AUROC) scores for each discriminative model trained using generated labels from the generative models.
The rows depict the relationship each model is trying to predict and the columns are the relationship specific sources each label function was sampled from. 
For example, the top-left most square depicts the discriminator model predicting Disease associates Gene (DaG) sentences, while randomly sampling label functions designed to predict the DaG relationship. 
The square towards the right depicts the discriminative model predicting DaG sentences, while randomly sampling label functions designed to predict the Compound treats Disease (CtD) relationship.
This pattern continues filling out the rest of the grid.
The last most column consists of pooling every relationship specific label function and proceeding as above.
](images/figures/label_sampling/disc_performance_test_set_auprc.png){#fig:discriminative_model_auprc}

## Discriminative Model Calibration
Deep learning models can be overconfident in their predictions. 
Based on this notion we calibrated the best performing discriminative model using a temperature scalling algorithm.
For Disease associates Gene (DaG) and Compound treats Disease (CtD) the model is calibrated for high prob predictions.
For CbG and GiG the model does not calibrate well.
The CbG model has the predicted probabilities shrinking into a domain of [0.2, 0.6].
For GiG edge most of the high predictions were overestimated and the predicted range is only between 0.4 and 0.6.

![
Calibration plots for the discriminative model.
A perfectly calibrated model would show a diagnoal line (dashed).
The blue line represents the predictions before calibration and the orange line shows predictions after calibration. 
](images/figures/model_calibration/model_calibration.png){#fig:discriminative_model_calibration}

## Reconstructing Hetionet
place figure of number of new edges that can be added to hetionet as well as edges we can reconstruct using this method
