## Results

### Generative Model Using Randomly Sampled Label Functions
![
Plot of AUROC scores for each generative model trained on randomly sampled label functions.
The headers depict the relationship each model is trying to predict and the colored points are the edge type specific sources from which each label function is sampled.
The 0th point represents our baseline model which only uses only distant supervision label functions.
](https://raw.githubusercontent.com/danich1/snorkeling/1b198264ea16fbd7ced7646907d955dd095bfc7e/figures/label_sampling_experiment/transfer_test_set_auroc.png){#fig:auroc_gen_model_test_set}

![
Plot of AUPR scores for each generative model trained on randomly sampled label functions.
The headers depict the relationship each model is trying to predict and the colored points represent the edge type specific sources from which each label function is sampled.
The 0th point represents our baseline model which only uses distant supervision label functions.
](https://raw.githubusercontent.com/danich1/snorkeling/1b198264ea16fbd7ced7646907d955dd095bfc7e/figures/label_sampling_experiment/transfer_test_set_aupr.png){#fig:aupr_gen_model_test_set}

We added randomly sampled label functions to a baseline for each edge type to evaluate the feasibility of label function re-use.
Our baseline model consisted of a generative model trained with only edge-specific distant supervision label functions.
We reported the results in AUROC and AUPR (Figures {@fig:auroc_gen_model_test_set} and {@fig:aupr_gen_model_test_set}; Supplemental Figures {@fig:auroc_gen_model_tune_set} and {@fig:auroc_gen_model_tune_set}).  
Performance increases as the number of edge-specific label functions gets added to the baseline model (Figures {@fig:auroc_gen_model_test_set} and {@fig:aupr_gen_model_test_set}). 
The Compound treats Disease (CtD) edge type is a quintessential example of this trend.
The baseline model starts off with an AUROC score of 52% and an AUPRC of 29%, then performance increases to 76% and 48% respectively as more CtD label functions are included. 
Gene interacts Gene (GiG), Disease associates Gene (DaG) and Compound binds Gene (CbG) edge types share a similar trend.
Baseline performance starts off with an AUROC of 57% for DaG,78% for CbG and 66% for GiG, then increases to 62% for DaG, 81% for CbG and 75% for GiG.
Regarding AUPR, the baseline starts off at 43% for DaG, 29% for CbG and 30% for GiG. then increases to 44%, 30% and 35% respectively.

We based our initial hypothesis on the idea that certain edge types would share similar linguistic features which would be particularly amenable to label function transfer.
For example, sentences for edges CbG and GiG typically describe physical interactions whether it be between a compound and a gene or a pair of two genes.
We observed that performance increased in terms of both AUROC and AUPR when using label functions from the GiG edge type to predict CbG edges (Figures {@fig:auroc_gen_model_test_set} and {@fig:aupr_gen_model_test_set}).
Likewise when using CbG label function to predict the GiG edge type; however, in both cases GiG label functions out performed the CbG label functions.
Regarding DaG, each label function source had similar performance when predicting the test set (Figures {@fig:auroc_gen_model_test_set} and {@fig:aupr_gen_model_test_set}).
When predicting the tune set it is clear that DaG specific label functions out performs the other sources. (Supplemental Figures {@fig:auroc_gen_model_tune_set} and {@fig:auroc_gen_model_tune_set}).

Lastly, we pooled together all non-database label functions then randomly sampled trained generative models to predict each edge type.
We report performance in terms of AUROC and AUPR (Figures {@fig:auroc_grabbag_gen_model_test_set} and {@fig:aupr_grabbag_gen_model_test_set}; Supplemental Figures @fig:auroc_grabbag_gen_model_tune_set} and @fig:aupr_grabbag_gen_model_tune_set}).
A general consensus for CbG, GiG and CtD edges is that using all label functions hurt performance.
The gap between edge specific sources and the all category widens as the number of label functions increases.
The only exception to this is DaG where performance increases (57% to 65% AUROC and 43% to 47% AUPR) as the number of label functions added to the baseline model increases.

Overall, only CbG and GiG show significant signs of transferability between each other for both Tune and Test set.
DaG shows conflicting results between the tune and test set, when it comes to sampling individual off-edge label functions; however, when pooling every label function together performance increases. 
In terms of CtD, only edge-specific label function increase performance, while off-edge label function hinders performance.

![
Plot of AUROC scores for each generative model trained on randomly sampled label functions from all edge types.
The headers depict the relationship each model is trying to predict and the colored points represent the edge type specific sources from which each label function is sampled.
The 0th point represents our baseline model which only uses distant supervision label functions.
The x-axis is relative to the all label function source samples.
](https://raw.githubusercontent.com/danich1/snorkeling/f16f37ade89ea82fbc3d2d6f9610c188952172b5/figures/label_sampling_experiment/all_lf_test_set_auroc.png){#fig:auroc_grabbag_gen_model_test_set}

![
Plot of AUPR scores for each generative model trained on randomly sampled label functions from all edge types.
The headers depict the relationship each model is trying to predict and the colored points represent the edge type specific sources from which each label function is sampled.
The 0th point represents our baseline model which only uses distant supervision label functions.
The x-axis is relative to the all label function source samples.
](https://raw.githubusercontent.com/danich1/snorkeling/f16f37ade89ea82fbc3d2d6f9610c188952172b5/figures/label_sampling_experiment/all_lf_test_set_aupr.png){#fig:aupr_grabbag_gen_model_test_set}
