## Results

### Generative Model Using Randomly Sampled Label Functions
![
Grid of AUROC scores for each generative model trained on randomly sampled label functions.
The rows depict the relationship each model is trying to predict and the columns are the edge type specific sources from which each label function is sampled.
The right most column consists of pooling every relationship specific label function and proceeding as above.
](https://raw.githubusercontent.com/danich1/snorkeling/ee638b4e45717a86f54a2744a813baaa90bc6b84/figures/label_sampling_experiment/transfer_test_set_auroc.png){#fig:auroc_gen_model_performance}

We added randomly sampled label functions to a baseline for each edge type to evaluate the feasibility of label function re-use.
Our baseline model consisted of a generative model trained with only edge-specific distant supervision label functions.
We reported the results in AUROC and AUPR (Figure {@fig:auroc_gen_model_performance} and Supplemental Figure {@fig:aupr_gen_model_performance}).  
The on-diagonal plots of figure {@fig:auroc_gen_model_performance} and supplemental figure {@fig:aupr_gen_model_performance} show increasing performance when edge-specific label functions are added on top of the  edge-specific baselines.
The CtD edge type is a quintessential example of this trend.
The baseline model starts off with an AUROC score of 52% and an AUPRC of 28%, which increase to 76% and 49% respectively as more CtD label functions are included. 
DaG edges have a similar trend: performance starting off with an AUROC of 56% and AUPR of 41% then increases to 62% and 45% respectively.
Both the CbG and GiG edges have an increasing trend but plateau after a few label functions are added.  

The off-diagonals in figure {@fig:auroc_gen_model_performance} and supplemental figure {@fig:aupr_gen_model_performance} show how performance varies when label functions from one edge type are added to a different edge type's baseline.
In certain cases (apparent for DaG), performance increases regardless of the edge type used for label functions.
In other cases (apparent with CtD), one label function appears to improve performance; however, adding more label functions does not improve performance (AUROC) or decreases it (AUPR).
In certain cases, the source of the label functions appears to be important: the performance of CbG edges decrease when using label functions from the DaG and CtD categories.

Our initial hypothesis was based on the idea that certain edge types capture similar physical relationships and that these cases would be particularly amenable for label function transfer.
For example, CbG and GiG both describe physical interactions.
We observed that performance increased as assessed by both AUROC and AUPR when using label functions from the GiG edge type to predict CbG edges.
A similar trend was observed when predicting the GiG edge; however, the performance differences were small for this edge type making the importance difficult to assess.  
The last column shows increasing performance (AUROC and AUPR) for both DaG and CtD when sampling from all label functions.
CbG and GiG also had increased performance when one random label function was sampled, but performance decreased drastically as more label functions were added.
It is possible that a small number of irrelevant label functions are able to overwhelm the distant supervision label functions in these cases (see Figure {@fig:auroc_random_label_function_performance} and Supplemental Figure {@fig:aupr_random_label_function_performance}).

### Random Label Function Generative Model Analysis
![
A grid of AUROC (A) scores for each edge type.
Each plot consists of adding a single label function on top of the baseline model.
This label function emits a positive (shown in blue) or negative (shown in orange) label at specified frequencies, and performance at zero is equivalent to not having a randomly emitting label function.
The error bars represent 95% confidence intervals for AUROC or AUPR (y-axis) at each emission frequency.
](https://raw.githubusercontent.com/danich1/snorkeling/ee638b4e45717a86f54a2744a813baaa90bc6b84/figures/gen_model_error_analysis/transfer_test_set_auroc.png){#fig:auroc_random_label_function_performance}

We observed that including one label function of a mismatched type to distant supervision often improved performance, so we evaluated the effects of adding a random label function in the same setting.
We found that usually adding random noise did not improve performance (Figure {@fig:auroc_random_label_function_performance} and Supplemental Figure {@fig:aupr_random_label_function_performance}).
For the CbG edge type we did observe slightly increased performance via AUPR (Supplemental Figure {@fig:aupr_random_label_function_performance}).
However, performance changes in general were smaller than those observed with mismatched label types.

### Text mined edges can expand a database-derived knowledge graph

![
Text-mined edges can recall a fair amount of existing edges as well as add a myraid amount of novel edges to Hetionet v1 
This bar chart shows the number of edges we can successfully recall in green and shows the number of new edges that can be added in blue.  
Percentages contained in parenthesis represent the fraction of edges we recalled over the total number of edges already contained in Hetionet v1.
For example, within the compound treats disease edge we can recall 85% of existing edges as well as add 6,088 novel edges.
](https://raw.githubusercontent.com/danich1/snorkeling/6e929e486537c5d105e393e20984b96910c96024/figures/edge_prediction_experiment/edges_added.png){#fig:hetionet_reconstruction}

Sentences need to be translated into edge representations before they are incorporated into Hetionet v1.
We used a calibrated discriminator model to score every candidate sentence within our dataset.
We grouped each candidate based on their mention pair and took the max score within each group.
Each group score represents the probability of the existence of an edge and we used a cutoff score that produced an equal error rate between the false positives and false negatives.
We quantified how many edges can be successfully recalled/added to Hetionet v1 (Figure {@fig:hetionet_reconstruction}) and report top ten high scoring sentences for each edge type in Supplemental Table {@tbl:edge_prediction_tbl}.

We are able to recall more than half of existing edges for all edge types.
Our best recall is with the Compound treats Disease (CtD) edge type, where we retain 85% of already established edges.
Plus, we can add over 6,000 new edges to that category.
In contrast, we could only recall close ot 70% of existing edges for the other cateogires; however, we can add over 40,000 novel edges to each category.
This sugests that Hetionet v1 is missing a compelling amount of biomedical information and that translating sentences to edge representation is a difficult task.
Overall, we can incorporate a multitude of new information in Hetionet v1 for all edge types.
