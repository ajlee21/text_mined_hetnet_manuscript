#Materials and Methods

##Dataset
Talk about dataset - Pubtator
Talk about preprocessing Pubtator
Talk about hand annotations for each realtion

## Label Functions
describe what a label function is and how many we created for each relation

## Training Models
### Generative Model
talk about generative model and how it works
### Word Embeddings
mention facebooks fasttext model and how we used it to train word vectors
### Discriminator Model
talk about the discriminator model and how it works
### Discriminator Model Calibration
talk about calibrating deep learning models with temperature smoothing

## Experimental Design
Being able to re-use label functions would significantly speed up the annotation process.
To test the viability of re-use we implemented a sampling with replacement approach.
For each relationship we trained a generative model using only label functions in the database category.
These models surve as our baseline.
Following the baseline models, we randomly sample a fixed number of label functions (five evenly spaced points between one and the total number of constructed functions) from both the text patterns and domain heuristics categories.
These sampled functions are incorporated on top of the baseline models.
We record performance of each sample in terms of area under the receiver operating characteristic curve (AUROC).
Following the generative model, we trained a discriminator model to build off of the generated labels produced from each sampled run.
The performance of the discriminator model is reported in terms of AUROC as well.
We repeat this sampling process 50 times for each specified sampled size.
