# Materials and Methods

## Dataset
We used PubTator [@doi:10.1093/nar/gkt441] as input to our analysis.
PubTator provides medline abstracts that have been annotated with well-established entity recognition tools including (X, Y, Z, ZZ, ZZZ...).
We downloaded PubTator on June 30, 2017, at which point it contained 10,775,748 abstracts.
We filtered out mention tags that were not contained in hetionet.
We then used the Stanford CoreNLP parser [@doi:10.3115/v1/P14-5010] to tag parts of speech and generate dependency trees.
We extracted sentences with two or more mentions, termed candidate sentences, and considered sentences with only a single mention to be negatives.
We performed a stratified sort (STRATIFIED BY?) to produce a training set, tuning set and a testing set (shown in Table 1).
Each sentence was sorted based on the present mention pair.
We hand labeled five hundred to a thousand candidate sentences of each relationship to obtain to obtain a ground truth set (Table 1).

Table 1. Statistics of Candidate Sentences. Numbers in parentheses show the number of positives and negatives that resulted from the hand-labeling process.

| Relationship | Train | Tune | Test |
| :--- | :---: | :---: | :---: |
| Disease Associates Gene | 2.35 M |31K (397+, 603-) | 313K (351+, 649-) |
| Compound Binds Gene | 1.7M | 468K (37+, 463-) | 227k (31+, 469-) |
| Compound Treats Disease | 1.013M | 96K (96+, 404-) | 32K (112+, 388-) |
| Gene Interacts Gene | 12.6M | 1.056M (60+, 440-) | 257K (76+, 424-) |

## Label Functions
describe what a label function is and how many we created for each relation

## Training Models
### Generative Model
talk about generative model and how it works
### Word Embeddings
mention facebooks fasttext model and how we used it to train word vectors
### Discriminator Model
talk about the discriminator model and how it works
### Discriminator Model Calibration
talk about calibrating deep learning models with temperature smoothing

## Experimental Design
talk about sampling experiment
