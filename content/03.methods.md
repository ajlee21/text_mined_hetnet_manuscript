# Materials and Methods

## Dataset
The dataset used for this project is called Pubtator [@doi:10.1093/nar/gkt441], which is an open source repository that contains pre-tagged medline abstracts.
It was downloaded on June 30, 2017 and contained 10,775,748 different abstracts.
After obtaining these abstracts, we filtered out mention tags that were not contained in hetionet.
Following the tag filtering step, we used the Stanford CoreNLP parser [@doi:10.3115/v1/P14-5010] to do part of speech (POS) tagging and dependency tree generation.
Treating sentences with only a single mention as negative, we extracted sentences with two or more mentions, termed candidate sentences. 
After obtaining candidate sentences, we did a stratified sort of each candiadte into a training set, tuning set and a testing set (shown in Table 1).
Each sentence was sorted based on the present mention pair.
To obtain a ground truth set for each given relationship, we hand labeled five hundred to a thousand candidate sentences (shown in parenthesis in Table 1).

Table 1. Statistics of Candidate Sentences

| Relationship | Train | Tune | Test |
| :--- | :---: | :---: | :---: |
| Disease Associates Gene | 2.35 M |31K (397+, 603-) | 313K (351+, 649-) |
| Compound Binds Gene | 1.7M | 468K (37+, 463-) | 227k (31+, 469-) |
| Compound Treats Disease | 1.013M | 96K (96+, 404-) | 32K (112+, 388-) |
| Gene Interacts Gene | 12.6M | 1.056M (60+, 440-) | 257K (76+, 424-) |

## Label Functions
describe what a label function is and how many we created for each relation

## Training Models
### Generative Model
talk about generative model and how it works
### Word Embeddings
mention facebooks fasttext model and how we used it to train word vectors
### Discriminator Model
talk about the discriminator model and how it works
### Discriminator Model Calibration
talk about calibrating deep learning models with temperature smoothing

## Experimental Design
talk about sampling experiment
