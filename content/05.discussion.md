## Discussion

We tested the feasibility of re-using label functions to extract relationships from literature.
Through our sampling experiment we found that adding relevant label functions increases prediction performance.
This can been seen in the on-diagonals of generative model performance plots (Figure {@fig:generative_model_auroc} and {@fig:generative_model_auprc}).
An interesting finding is performance increases when text patterns and domain heuristic label functions are added on top of the distant supervision label functions. 
This increase happens because curated databases have low coverage and end up missing information.  
Some relationships are easier to predict than others.
For example, we achieved a significantly high area under the receiver operating curve (AUROC) and area under the precision recall curve (AUPR) for Compound-treats-Disease (CtD) (Figure {@fig:generative_model_auroc} and {@fig:generative_model_auprc}).
Reason for high performance is that wording is pretty straight forward when abstracts talk about this particular edge type.
Regarding Disease-associates-Gene (DaG), this edge type has a broad range of keywords that can infer associations.
For an association a gene could be up-regulated, down-regulated or found within a GWAS study.
Because of this loose criteria, the generative model's performance increased regardless of label function source.
Meanwhile performance for Compound-binds-Gene (CbG) and Gene-interacts-Gene (GiG) remains modest.  
For the off diagonals the generative model's performance varied based on edge type pair. 
CbG and GiG edge types have shared keywords and sentence structure.
This shared information resulted in an increased AUROC and AUPR when both edges predict one another.
When using DaG and CtD to predict CbG and DaG performance starts to increase for one randomly sampled label function then drastically decreases.
The reason for this spike is that majority of the sampled label functions have a negative polarity.
This polarity offsets the distant supervision label functions and makes the generative model predict more sentences as negative.
These two edge types have a negative bias in their evaluation sets (Table {@tbl:candidate-sentences}), which results in increased AUROC and AUPR.  
After tuning the generative model, we assessed the discriminative model's performance.
The discriminative model has a tendency to overfit towards the generative model. 
Looking at figures {@fig:discriminative_model_auroc} and {@fig:discriminative_model_auprc}, the discriminative model's performance is correlated with the generative model.
The exception to this trend is the CtD edge type.
Performance does well the beginning and then deteriorates. 
This high performance is a result of the simple language this edge type has (mentioned above).
More regularization is required to prevent this overfitting trend.  
Deep learning models have a tendency to be overconfident in their predictions.
To account for this problem we performed model calibration for our discriminative model.
As shown in figure {@fig:discriminative_model_calibration} the discriminative model for DaG and CtD calibrates well.
Coincidently, these two edge types have high performance in both AUROC and AUPR for the generative and discriminative model.
This suggests the more accurate the model the easier it is to calibrate its predictions. 
On the contrary CbG and GiG have poor calibration.
This is due to a class imbalance for both edge types as only 7% and 12% of annotated sentences were labeled positive (Table {@tbl:candidate-sentences}).
As mentioned previously this class imbalance affected performance for both the generative model and the discriminative model.  
Lastly, we evaluated our model's ability to reconstruct hetionet v1 as well as compared its performance against a literature model.
Our model performed just as well as the literature model for AUROC (Fig. {@fig:cocoscore_comparison}).
For AUPR our model was outperformed.
Reason for this is that our model predicted a lot of unseen edges as positive.
Since we are treating unseen edges as negative, our model shows a decrease in precision.
Despite the under performance, we were still able to identify new edges that Hetionet v1 may have missed (fig. {@fig:hetionet_reconstruction}). 
For CtD and DaG we were able to retain some established edges with 100% precision level.
Again this can be attributed to the high performing discriminative and generative models.
As for CbG and GiG our discriminative model fails to reach 100% precision, because these two edge types suffer from a class imbalance problem.
