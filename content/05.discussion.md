## Discussion

We measured the extent to which label functions can be re-used across multiple edge types to extract relationships from literature.
Through our sampling experiment, we found that adding edge-specific label functions increases performance for the generative model ({@fig:auroc_gen_model_performance}.
We found that label functions designed from relatively related edge types can increase performance (Gene interacts Gene (GiG) label functions predicting the Compound binds Gene (CbG) edge and vice versa), while the Disease associates Gene (DaG) edge type remained agnostic to label function source (Figure {@fig:auroc_gen_model_performance} and Supplemental Figure {@fig:aupr_gen_model_performance}).
Furthermore, we found that using all label functions at once generally hurts performance with the exception of DaG (Figure {@fig:auroc_grabbag_gen_model_test_set} and Supplemental Figure {@fig:aupr_grabbag_gen_model_test_set}).
We premise that DaG is a broadly defined edge type, e.g. can contain sentences from other edge types such as Disease (up/down)regulating a gene, which makes it agnostic to label function sources.  

Regarding the discriminator model, adding edge-specifc label function immensely improved performance for two out of the four edge types (Compound treats Disease (CtD) and DaG) ({@fig:auroc_disc_model_performance}). 
GiG and CbG discriminator models showed minor improvements over the generative model, but only when close to all edge-specific label functions are included.
Potential reason for poor performance is the negative class bias both edge types had (Table {@tbl:candidate-sentences}).
Plus, the GiG dataset contained a prodigious amount of spurious gene mentions, because Pubtator [@doi:10.1093/nar/gkt441] tags gene abbrevations along with gene symbols.
Despite discriminator models' performance, we encounted difficulty in calibrating each model (Figure {@fig:discriminative_model_calibration}).
The temperature scaling algorithm is able to calibrate the high scores for each model, but could not fully calibrate each model overall. 
A possible reason for poor calibration is that our labeled datasets are too small (Table {@tbl:candidate-sentences}) and calibration could improve with more examples.
We recalled a great number of existing edges in Hetionet v1 edges as well as detect over thousands of new edges to each edge type (Figure {@fig:hetionet_reconstruction}).
Overall, our findings highlight that this framework can effeciently extract relationships and show that it can establish edges within Hetionet v1.  
 

