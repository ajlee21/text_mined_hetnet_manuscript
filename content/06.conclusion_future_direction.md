## Conclusion and Future Direction

Filling out knowledge bases via manual curation can be an arduous and erroneous task.
With the increased rate of publications manual curation becomes an infeasible approach.
Data programming, a paradigm that uses label functions a means to speed up the annotation process, can be used as a solution to speed up this non-trivial task.
The caveat to using this paradigm is the time consuming task of creating a useful label function.
To attempt to speed up researcher time we tested the feasibility of resuing label functions to quickly annotate and train machine learning models.
Based on our results, we conclude that label functions can be reused across edge types.
Negative label functions can be universally shared, while positive label functions can only be shared based on edge type.
We also note that the number of edge specific label functions correlates with prediction performance.
When using this paradigm the discrminitive model has a tendency to overfit to the generative model.
This can be resolved by using regularization techinques, such as weight decay and drop out.
Lastly, we plan to build off this model by construct a unified system to extract multiple relationships at once (multitask learning).
By building this system we quickly scale Hetionet as well as provide researchers with quick access to new findings and publications.
